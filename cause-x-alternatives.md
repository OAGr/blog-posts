# Consider Searching for Innovations A-立, not Cause X.

Many of my conversations around Cause X have made me uncomfortable. I'm sure this wasn't the original intention, but I think the frame of Cause X has led to some incorrect assumptions.

Some statements I disagree or are very unsure about:

- "We haven't found Cause X yet, so we're not making much progress."

- "It's been more than a decade since people discovered AI risk. We haven't found anything similarly large since, so we're slowing down."

- "Finding Cause X is one of the most effective things we could currently be working on."

- "Cause X is probably something we haven't even thought about yet, and it's also probably very valuable we work now to figure out what it is."

  

## Independent vs. Causal Models of Innovation

First, let's consider two simple models of intellectual progress. 

**The Independent Model**

In the independent model, each major innovation is distinct from the previous ones. Perhaps one reasonable example of this is Pixar filmmaking. They started things with the Toy Story franchise, then later moved on to very different films like A Bug's Life, Monsters, Inc. and Finding Nemo. Perhaps you could say that each of these involved educational lessons that carried on to the others, but I think it's fair to say that each is similarly different to the others. 

**The Subset Model**

With the subset model, the main future innovations happen within the previous ones. Initial innovations are limited in scope, but expand over time, with specific subsets driving that expansion.

For example, the invention and development of electrical engineering was highly significant. It led to the development of computers, which led to the development of computer science, which led to the development of artificial intelligence, which led to the development of deep learning.

It's easy to imagine a skeptic of computer science saying something like, "That's not *truly* innovative, it's just a branch of electrical engineering. A *true* innovation would be unique from electrical engineering."

While it may be true that computer science may have been enabled or initialized from electrical engineering, that doesn't mean that the field hasn't come with many unique and important innovations and practices. 

In a way one could say that Thomas Edison and Nikola Tesla were responsible for electricity and everything it led to, but I think that's a perspective that's not particularly informative or useful. Arguably their work led from other engineering and mathematical studies, which could be traced back to Euclid and Aristotle, which could be traced back further still.

**Effective Altruism and Subset Innovations**

Arguably, existential risks were found as a subset of Effective Altruism or Utilitarian. Existential risk research partially led to a recognized importance and study of AI and Bio risks, which have led to more specialized research areas. 

In a way, the choice of trying to identify new cause specifically is a bit arbitrary. One could also consider backing up all the way and trying to find new alternatives to Effective Altruism, or narrowing all the way and finding alternatives to [Iterated Distillation and Amplification](https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616?gi=7cc42b5c7a96).



## Highly Novel Ideas Often Aren't Practical

In his [talk transcript](https://www.effectivealtruism.org/articles/moral-progress-and-cause-x/) on Cause X, Will MacAskill stated,

> Perhaps the most exciting or interesting way in which the EA community could have a huge positive impact on the world is **if we can drive forward moral progress and figure out the problems, the Cause X, that we're not even aware of today.****

I'm skeptical of that Cause X needs to be something we're not aware of, though perhaps for different reasons than from the independent/subset argument above.

My strong guess is that the most important innovations that will be discovered in the next few years, around Effective Altruism, are ones that we are at least vaguely aware of today. 

There are two main reasons for this:

1. **Novel ideas that will eventually be important will become easier to discover in the future.**
2. **Highly novel ideas are often not yet useful.**

As a concrete example, it would have been very difficult for someone to have made advances in AI before there was common electricity usage. It was possible. Ada Lovelace wrote programs and discussed AI around 1845. Advances in AI were in many ways more novel and innovative than advances in contemporary technologies. However, they were both very difficult to produce, and also not very relevant. Further programming innovations in 1845 would have had very little utility until computers came along, at which point they would have been far easier to discover anyway.

Many of the Effective Altruist ideas that are regarded as the most novel also seem like the most impractical. Early AGI safety work was done before Deep Learning, after which priorities changed significantly. Wild animal suffering is a really interesting idea, but it may be quite a while longer before it could start being applied to things. 

## Lots of Quantity can Overpower Quality

One last issue with "Cause X." The obvious emphasis in the eventual impact is on the "discovery" of the cause, rather than the innovation around that work. A naive read of this would suggest that we need "one great thinker" with "one brilliant idea." Sometimes these are quite useful, but I think this scenario is [significantly overplayed](https://en.wikipedia.org/wiki/Great_man_theory#Herbert_Spencer's_Criticism).

Take startups. Startup ideas are considerably overvalued by most people outside the startup scene. The reality is that founders can make very little money by "selling" their ideas to other people. There's actually no real market for this that I'm aware of, besides selling to patent troll like entities. The vast majority of a company's valuation comes not from its' initial idea, but rather the talent, infrastructure, position, and proof that comes with it. 

With philosophical intellectual work, the equivalent may be in significant amounts of research and ideation that go into fleshing out any basic concept. For example, one person could have the idea that "It's possible that distributing malaria nets is useful", but a huge amount of work is still necessary to properly understand the practical considerations and cost effectiveness of such work. A good randomized control trial could cost millions, while hypothetically it could have cost us a few thousand dollars to come up with the basic idea if we were effectively crowdsourcing it.

## Alternative Perspectives

This is not to say that I think the Effective Altruist community is trying to be *too innovative*, but rather that some of the focus may be misguided. 

To possibly brainstorm some other things to think about, consider,

- "Moral Philosophy X"  
- "Consequentialist System X"  
- "AI Alignment Techniques A-立*" (Just a whole lot of approaches)   
- "Global AGI Treaty Variants A-立"   

To be clear, I do think that work on both exploring possible candidates for Cause X is likely useful, just not significantly more useful than many other things people could be researching.

## Take Aways

So, in summary, I would suggest these three updates to those interested in "Cause X."

1. Consider searching for significant innovations in the existing research areas. Future research areas are likely to come from subsets of existing ones, rather than being completely separate.
2. It's OK to prioritize research in explored areas, especially if these areas are practical in the short-term. There's probably a lot of innovation to be done in these areas still.
3. You can make a lot of progress without coming up with particularly ground-breaking ideas. There are many metrics one could use for research success, and many good ones would favor impact over novelty.



*I use 立 to indicate that the list has gone far past 26 items and through other languages.

