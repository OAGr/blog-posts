[Epistemic status: rough ideas, quickly written]

It seems like a curse for great ideas to be taken out of context and misunderstood. I fear that some of that may have happened around "Cause X."

Some statements I find questionable:

- "We haven't found Cause X yet, so we're not making much progress."
- "It's been more than a decade since people discovered AI risk. We haven't found anything similarly large since, so we're slowing down."
- "Finding Cause X is one of the most effective things we could currently be working on."
- "Cause X is probably something we haven't even thought about yet, and it's also probably very valuable we work now to figure out what it is."

## Issue #1: Innovation often happens within previous innovations

Let's consider two simple models of intellectual progress. 

**The Independent Model**

In the independent model, each major innovation is distinct from the previous ones. Perhaps one reasonable example of this is the discovery of new pharmaceuticals drugs. Drug discovery is a very expensive process that happens in parallel; many very different processes would be tried with little overlap. After one drug is both discovered and tested, the innovations behind that aren't necessarily useful for the finding of other drugs.  

**The Subset Model**

With the subset model, the main future innovations happen within the previous ones. Initial innovations are limited in scope, but expand over time, with specific subsets driving that expansion.

For example, the invention and development of electrical engineering was highly significant. It led to the development of computers, which led to the development of computer science, which led to the development of artificial intelligence, which led to the development of deep learning.

It's easy to imagine a skeptic of computer science saying something like, "That's not *truly* innovative, it's just a branch of electrical engineering. A *true* innovation would be unique from electrical engineering."

While it may be true that computer science may have been enabled or initialized from electrical engineering, that doesn't mean that the field hasn't come with many unique and important innovations and practices. 

In a way one could say that Thomas Edison and Nikola Tesla were responsible for electricity and everything it led to, but I think that's a perspective that's not particularly informative or useful. Arguably their work led from other engineering and mathematical studies, which could be traced back to Euclid and Aristotle, which could be traced back further still.

**Effective Altruism and Subset Innovations**

Arguably, existential risks were found as a subset of Effective Altruism or Utilitarianism. Existential risk research partially led to the recognized importance and study of AI and Bio risks, which have led to more specialized research areas. 

This may highlight the fact that the choice of trying to identify a new **cause** specifically, for Cause X, is a bit arbitrary. One could also consider backing up all the way and trying to find new alternatives to Effective Altruism, or narrowing all the way and finding alternatives to [Iterated Distillation and Amplification](https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616?gi=7cc42b5c7a96).

The important point here is that there could be very important innovative potential in all of the causes or above them. Judging or focussing on innovation in the specific area of "new causes" is useful when discussing that particular topic, but shouldn't be considered reflective of overall progress.

## Issue #2: Highly novel ideas can be overvalued

In his [talk transcript](https://www.effectivealtruism.org/articles/moral-progress-and-cause-x/) on Cause X, Will MacAskill stated,

> Perhaps the most exciting or interesting way in which the EA community could have a huge positive impact on the world is **if we can drive forward moral progress and figure out the problems, the Cause X, that we're not even aware of today.****

I'm skeptical that Cause X needs to be something we're not aware of, though perhaps for different reasons than from the independent/subset argument above.

My strong guess is that the most effective* innovations that will be discovered in the next few years, around Effective Altruism, are ones that we are at least vaguely aware of today. 

There are two main reasons for this:

1. **Highly novel ideas are often not yet useful.**
2. **Highly novel ideas that will be useful only in the far future will likely get easier to discover anyway.**

As a concrete example, it would have been very difficult for someone to have made advances in AI before there was common electricity usage. It was possible. Ada Lovelace wrote programs and discussed AI around 1845. Advances in AI were in many ways more novel and innovative than advances in contemporary technologies. However, they were both very difficult to produce, and also not very relevant. Further programming innovations in 1845 would have had very little utility until computers came along, at which point they would have been far easier to discover anyway.

Many of the Effective Altruist ideas that are regarded as the most novel also seem like the most impractical. Early AGI safety work was done before Deep Learning, after which priorities changed significantly. Work around negotiation around AGIs is very new, but it's possible they won't be very decision relevant for a while.

## Issue #3: There's a lot of important work around "one single great insight"

One last issue with "Cause X." The obvious emphasis in the eventual impact is on the "discovery" of the cause, rather than the innovation around that work. A naive read of this would suggest that we need "one great thinker" with "one brilliant idea." Sometimes these are quite useful, but I think this scenario is [significantly overplayed](https://en.wikipedia.org/wiki/Great_man_theory#Herbert_Spencer's_Criticism).

Take startups. Startup ideas are considerably overvalued by most people outside the startup scene. The reality is that founders can make very little money by "selling" their ideas to other people. There's actually no real market for this that I'm aware of, besides selling to patent trolls. The vast majority of a company's valuation comes not from its' initial idea, but rather the talent, infrastructure, position, and proof that comes with it. 

With philosophical intellectual work, the equivalent may be in significant amounts of research and ideation that go into fleshing out any basic concept. For example, one person could have the idea that "It's possible that distributing malaria nets is useful", but a huge amount of work is still necessary to properly understand the practical considerations and cost effectiveness of such work. A good randomized control trial could cost millions, while hypothetically it could have cost us a few thousand dollars to come up with the basic idea if we were effectively crowdsourcing it.

## Alternative Perspectives

This is not to say that I think the Effective Altruist community is trying to be *too innovative*, but rather that some of the focus may be misguided. 

To possibly brainstorm some other things to think about, consider,

- "Moral Philosophy X"  
- "Consequentialist System X"  
- "AI Alignment Techniques A-Ω*" (Just a whole lot of approaches)   
- "Global AGI Treaty Variants A-Ω"   

To be clear, I do think that work on both exploring possible candidates for Cause X is likely useful, just not significantly more useful than many other things people could be researching.

## Take Aways

So, in summary, I would suggest these three updates to those interested in "Cause X."

1. Consider searching for significant innovations in the existing research areas. Future research areas are likely to come from subsets of existing ones, rather than being completely separate.

2. It's fine to prioritize research in explored areas, especially if these areas are practical in the short-term. There's probably a lot of innovation to be done in these areas still.

3. You can make a lot of progress without coming up with particularly ground-breaking ideas. There are many metrics one could use for research success, and many good ones would favor impact over novelty.

   

*I use "effective" here to refer to the fact that these innovations have the most value at this time. "Important" is a difficult word, because the "highly novel" ideas may eventually be highly important, but aren't yet.

*I use Ω to indicate that the list has gone far past 26 items and through other languages.

